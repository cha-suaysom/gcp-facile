{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code connects to GCP Kubernetes workload and perform simple MNIST prediction. Observe the following\n",
    "1. Most time is spent on connecting to the server, while the code in GCP would be much quicker since server is closer.\n",
    "2. After the first or second connection, the thread moves to another clientID and already \"warms up\", so the server connection is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging, grpc, time\n",
    "import numpy as np\n",
    "\n",
    "import server_tools_pb2\n",
    "import server_tools_pb2_grpc\n",
    "\n",
    "PORT = '50051'\n",
    "f = open(\"IP.txt\")\n",
    "IP = f.read()\n",
    "if IP[-1] == '\\n':\n",
    "    IP = IP[:-1]\n",
    "f.close()\n",
    "\n",
    "# Set this flag to indicate whether the client should wait until the prediction\n",
    "# is finished or check in with the server periodically until it is \n",
    "WAIT = False\n",
    "\n",
    "# Change this parameter depending on how many images you want to send at once.\n",
    "# There is an upper limit (668 on my machine) where the size of the package \n",
    "# becomes too great and the client will throw an error.\n",
    "NUM_IMAGES = 668\n",
    "\n",
    "def run():\n",
    "    # Get a handle to the server\n",
    "    channel = grpc.insecure_channel(IP + ':' + PORT)\n",
    "    stub = server_tools_pb2_grpc.MnistServerStub(channel)\n",
    "\n",
    "    # Get a client ID which you need to talk to the server\n",
    "    try:\n",
    "        response = stub.RequestClientID(server_tools_pb2.NullParam())\n",
    "    except:\n",
    "        print(\"Connection to the server could not be established. Press enter to try again.\")\n",
    "        return\n",
    "    client_id = response.new_id\n",
    "\n",
    "    # Generate lots of data\n",
    "    data = np.random.rand(NUM_IMAGES, 28, 28, 1)\n",
    "    data = data.tostring()\n",
    "\n",
    "    # Send the data to the server and receive an answer\n",
    "    start_time = time.time()\n",
    "    if WAIT:\n",
    "        print(\"Submitting images and waiting\")\n",
    "        response = stub.StartJobWait(server_tools_pb2.DataMessage(images=data, client_id=client_id, batch_size=32))\n",
    "    else:\n",
    "        print(\"Submitting images\")\n",
    "        try:\n",
    "            idPackage = stub.StartJobNoWait(server_tools_pb2.DataMessage(images=data, client_id=client_id, batch_size=32))\n",
    "        except:\n",
    "            print(\"NUM_IMAGES is too high\")\n",
    "            return\n",
    "        response = stub.ProbeJob(idPackage)\n",
    "        print(\"Checking in with server\")\n",
    "        while not response.complete:\n",
    "            response = stub.ProbeJob(idPackage)\n",
    "            if response.error != '':\n",
    "                print(response.error)\n",
    "                break\n",
    "\n",
    "    # Print output\n",
    "    original_array = np.frombuffer(response.prediction).reshape(NUM_IMAGES, 10)\n",
    "    whole_time = time.time() - start_time\n",
    "    print(\"Total time:\", whole_time)\n",
    "    print(\"Predict time:\", response.infer_time)\n",
    "    print(\"Fraction of time spent not predicting:\", (1 - response.infer_time / whole_time) * 100, '%')\n",
    "    channel.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting images\n",
      "Checking in with server\n",
      "Total time: 11.17451024055481\n",
      "Predict time: 0.705836296081543\n",
      "Fraction of time spent not predicting: 93.68351470545971 %\n",
      "Submitting images\n",
      "Checking in with server\n",
      "Total time: 22.498075246810913\n",
      "Predict time: 0.8005023002624512\n",
      "Fraction of time spent not predicting: 96.44190762329359 %\n",
      "Submitting images\n",
      "Checking in with server\n",
      "Total time: 8.726824522018433\n",
      "Predict time: 0.7406020164489746\n",
      "Fraction of time spent not predicting: 91.51349938823246 %\n",
      "Submitting images\n",
      "Checking in with server\n",
      "Total time: 8.583730697631836\n",
      "Predict time: 0.7114744186401367\n",
      "Fraction of time spent not predicting: 91.7113613683567 %\n",
      "Submitting images\n",
      "Checking in with server\n",
      "Total time: 9.714072942733765\n",
      "Predict time: 0.7159483432769775\n",
      "Fraction of time spent not predicting: 92.62978209554711 %\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig()\n",
    "for i in range(5):\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
